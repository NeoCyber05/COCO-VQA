{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Dataset",
   "id": "c827a83710a8b13"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-18T13:12:36.239552Z",
     "start_time": "2025-05-18T13:12:36.224922Z"
    }
   },
   "source": "import os",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:28:55.409264Z",
     "start_time": "2025-05-18T13:28:55.399228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data(data_path):\n",
    "    data = []\n",
    "\n",
    "    with open(data_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            part = line.strip().split(\"\\t\")\n",
    "            image_id = part[0]\n",
    "            image_id = image_id.split(\"#\")\n",
    "            image_id = image_id[0]\n",
    "            remaining_part = part[1]\n",
    "            # Tách  (remaining_part) thành câu hỏi và câu trả lời\n",
    "            QA = remaining_part.strip().split(\"?\", 1)\n",
    "            question = QA[0]\n",
    "            answer = QA[1]\n",
    "            answer = answer.strip()\n",
    "            data_sample = {\n",
    "                'question': QA[0] + '?',\n",
    "                'image_path': image_id,\n",
    "                'answer': answer\n",
    "            }\n",
    "            data.append(data_sample)\n",
    "\n",
    "    return data"
   ],
   "id": "c629a4d762ae0671",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:12:36.364819Z",
     "start_time": "2025-05-18T13:12:36.336016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_path = os.path.join(\"..\", \"data_coco\", \"vaq2.0.TrainImages.txt\")\n",
    "val_path = os.path.join(\"..\", \"data_coco\", \"vaq2.0.DevImages.txt\")\n",
    "test_path = os.path.join(\"..\", \"data_coco\", \"vaq2.0.TestImages.txt\")\n",
    "\n",
    "train_data=load_data(train_path)\n",
    "val_data=load_data(val_path)\n",
    "test_data=load_data(test_path)\n"
   ],
   "id": "9463d006449c8dd9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:12:36.411766Z",
     "start_time": "2025-05-18T13:12:36.398249Z"
    }
   },
   "cell_type": "code",
   "source": "print(train_data[0])",
   "id": "a86001907c9d80d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Is this a creamy soup ?', 'image_path': 'COCO_val2014_000000393225.jpg', 'answer': 'no'}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Process",
   "id": "db35842602f54415"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:12:37.611798Z",
     "start_time": "2025-05-18T13:12:36.560706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "from torchtext.vocab import build_vocab_from_iterator\n"
   ],
   "id": "892e7e958898f266",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:12:38.220575Z",
     "start_time": "2025-05-18T13:12:37.629670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def get_token(data_iters):\n",
    "    for sample in data_iters:\n",
    "        question = sample['question']\n",
    "        yield [token.text for token in nlp.tokenizer(question)]\n",
    "\n",
    "\n",
    "vocab = build_vocab_from_iterator(\n",
    "    get_token(train_data),\n",
    "    min_freq=1,\n",
    "    specials=[\"<unk>\", \"sos\", \"eos\", \"<pad>\"],\n",
    "    special_first=True\n",
    ")\n",
    "vocab.set_default_index(vocab[\"<unk>\"])#Nếu một token.text không có trong vocab, nó sẽ được gán ID của <unk>"
   ],
   "id": "5a80d245d79b662c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:12:38.267779Z",
     "start_time": "2025-05-18T13:12:38.253385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Độ dài cố định để xử lý theo batch\n",
    "def tokenize(question_text, max_seq_len= 20):\n",
    "    spacy_tokens = nlp.tokenizer(question_text)\n",
    "    #  Chuyển các token thành ID số sử dụng vocab\n",
    "    # Chúng ta cần lấy .text của mỗi  Token để tra cứu trong vocab\n",
    "    numerical_sequence = [vocab[token.text] for token in spacy_tokens]\n",
    "    current_len = len(numerical_sequence)\n",
    "    if current_len < max_seq_len:\n",
    "        padding_needed = max_seq_len - current_len\n",
    "        numerical_sequence += [vocab['<pad>']] * padding_needed\n",
    "    elif current_len > max_seq_len:\n",
    "        numerical_sequence = numerical_sequence[:max_seq_len]\n",
    "    return numerical_sequence"
   ],
   "id": "f9eb1d8706463891",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:12:38.314100Z",
     "start_time": "2025-05-18T13:12:38.301566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "example = \"Hello World!\"\n",
    "print(tokenize(example))"
   ],
   "id": "54631242d58f928e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:12:38.361311Z",
     "start_time": "2025-05-18T13:12:38.346809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classes = set([sample['answer'] for sample in train_data])\n",
    "classes_to_idx = {\n",
    "    cls_name: idx for idx, cls_name in enumerate(classes)\n",
    "}\n",
    "idx_to_classes = {\n",
    "    idx: cls_name for idx, cls_name in enumerate(classes)\n",
    "}\n",
    "print(idx_to_classes)"
   ],
   "id": "e0f8672905087fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'yes', 1: '? yes', 2: 'no', 3: '? no', 4: '\" ? no'}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pytorch Dataset",
   "id": "8fb8c82438f7b23a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:15:09.492867Z",
     "start_time": "2025-05-18T13:15:09.481353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms"
   ],
   "id": "e538e7629086c6ca",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:12:38.454185Z",
     "start_time": "2025-05-18T13:12:38.441011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class VQADataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        classes_to_idx,\n",
    "        max_seq_len=20,       # Độ dài tối đa của chuỗi câu hỏi (mặc định là 20)\n",
    "        transform=None,\n",
    "        root_dir='/data_coco/val2014-resized/'\n",
    "    ):\n",
    "        self.transform = transform\n",
    "        self.data = data\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.root_dir = root_dir\n",
    "        self.classes_to_idx = classes_to_idx\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.data[idx]['image_path'])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.tranform:\n",
    "            img = self.tranform(img)\n",
    "        question = self.data[idx]['question']\n",
    "        question = tokenize(question, self.max_seq_len)\n",
    "        question = torch.tensor(question, dtype = torch.long)\n",
    "\n",
    "        answer = self.data[idx]['answer']\n",
    "        answer = self.classes_to_idx[answer]\n",
    "        answer = torch.tensor(answer, dtype = torch.long)"
   ],
   "id": "8c35b73b1f11cf49",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DataLoader",
   "id": "796de8a42ed8a101"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:16:47.550486Z",
     "start_time": "2025-05-18T13:16:47.541460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "                    (0.485, 0.456, 0.406),\n",
    "                    (0.229, 0.224, 0.225)\n",
    "        ),\n",
    "    ]\n",
    ")"
   ],
   "id": "28cd51c0e3fa22c",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-18T13:17:28.735203Z",
     "start_time": "2025-05-18T13:17:28.723679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = VQADataset(train_data, classes_to_idx, transform=transform)\n",
    "val_dataset = VQADataset(val_data, classes_to_idx, transform=transform)\n",
    "test_dataset = VQADataset(test_data, classes_to_idx, transform=transform)"
   ],
   "id": "8c8659fc4d00f43",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e907ab49ba935211"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
